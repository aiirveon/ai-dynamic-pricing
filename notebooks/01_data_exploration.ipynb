{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Dynamic Pricing for UK Coffee Shops - Data Exploration\n",
    "\n",
    "**Phase 1: MVP & Baseline Model**\n",
    "\n",
    "Author: Osaheni  \n",
    "Date: November 2025\n",
    "\n",
    "## Purpose\n",
    "- Load and explore coffee sales data\n",
    "- Engineer features for ML model\n",
    "- Build baseline XGBoost model  \n",
    "- Establish pricing opportunity\n",
    "\n",
    "## Key Outputs\n",
    "- `coffee_sales_cleaned.csv` (with engineered features)\n",
    "- `baseline_xgboost.pkl` (trained model)\n",
    "- Baseline performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "âœ… SETUP COMPLETE - Libraries Imported\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Setup and Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"âœ… SETUP COMPLETE - Libraries Imported\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ“‚ STEP 1: LOADING ORIGINAL DATA\n",
      "======================================================================\n",
      "\n",
      "âœ… Loaded 3,547 transactions\n",
      "ðŸ“… Columns: 11\n",
      "\n",
      "ðŸ“‹ Column names:\n",
      "   ['hour_of_day', 'cash_type', 'money', 'coffee_name', 'Time_of_Day', 'Weekday', 'Month_name', 'Weekdaysort', 'Monthsort', 'Date', 'Time']\n",
      "\n",
      "âœ… coffee_name column present with 8 unique types\n",
      "\n",
      "ðŸ“Š Sample data:\n",
      "         Date             Time    coffee_name  money\n",
      "0  2024-03-01  10:15:50.520000          Latte   38.7\n",
      "1  2024-03-01  12:19:22.539000  Hot Chocolate   38.7\n",
      "2  2024-03-01  12:20:18.089000  Hot Chocolate   38.7\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Load Original Data\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ“‚ STEP 1: LOADING ORIGINAL DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load original coffee sales data\n",
    "df = pd.read_csv('../data/Coffe_sales.csv')\n",
    "\n",
    "print(f\"\\nâœ… Loaded {len(df):,} transactions\")\n",
    "print(f\"ðŸ“… Columns: {len(df.columns)}\")\n",
    "print(f\"\\nðŸ“‹ Column names:\")\n",
    "print(f\"   {list(df.columns)}\")\n",
    "\n",
    "# Verify coffee_name exists\n",
    "if 'coffee_name' in df.columns:\n",
    "    print(f\"\\nâœ… coffee_name column present with {df['coffee_name'].nunique()} unique types\")\n",
    "else:\n",
    "    raise KeyError(\"ERROR: coffee_name column not found in source CSV!\")\n",
    "\n",
    "# Show first few rows\n",
    "print(f\"\\nðŸ“Š Sample data:\")\n",
    "print(df[['Date', 'Time', 'coffee_name', 'money']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ” STEP 2: DATA QUALITY CHECK\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Dataset Shape: (3547, 11)\n",
      "\n",
      "ðŸ“ˆ Data Types:\n",
      "hour_of_day      int64\n",
      "cash_type       object\n",
      "money          float64\n",
      "coffee_name     object\n",
      "Time_of_Day     object\n",
      "Weekday         object\n",
      "Month_name      object\n",
      "Weekdaysort      int64\n",
      "Monthsort        int64\n",
      "Date            object\n",
      "Time            object\n",
      "dtype: object\n",
      "\n",
      "ðŸ” Missing Values:\n",
      "   âœ… No missing values!\n",
      "\n",
      "ðŸ’° Price Statistics:\n",
      "   Mean: Â£31.65\n",
      "   Min:  Â£18.12\n",
      "   Max:  Â£38.70\n",
      "   Std:  Â£4.88\n",
      "\n",
      "â˜• Coffee Types: 8\n",
      "coffee_name\n",
      "Americano with Milk    809\n",
      "Latte                  757\n",
      "Americano              564\n",
      "Cappuccino             486\n",
      "Cortado                287\n",
      "Hot Chocolate          276\n",
      "Cocoa                  239\n",
      "Espresso               129\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Basic Data Exploration\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ” STEP 2: DATA QUALITY CHECK\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Dataset info\n",
    "print(f\"\\nðŸ“Š Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nðŸ“ˆ Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Missing values\n",
    "print(f\"\\nðŸ” Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"   âœ… No missing values!\")\n",
    "else:\n",
    "    print(missing[missing > 0])\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nðŸ’° Price Statistics:\")\n",
    "print(f\"   Mean: Â£{df['money'].mean():.2f}\")\n",
    "print(f\"   Min:  Â£{df['money'].min():.2f}\")\n",
    "print(f\"   Max:  Â£{df['money'].max():.2f}\")\n",
    "print(f\"   Std:  Â£{df['money'].std():.2f}\")\n",
    "\n",
    "print(f\"\\nâ˜• Coffee Types: {df['coffee_name'].nunique()}\")\n",
    "print(df['coffee_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ• STEP 3: DATETIME PARSING\n",
      "======================================================================\n",
      "\n",
      "âœ… Date parsed: 2024-03-01 to 2025-03-23\n",
      "âœ… All 3,547 datetimes parsed successfully\n",
      "   Range: 2024-03-01 10:15:50 to 2025-03-23 18:11:38\n",
      "\n",
      "â° Extracted hour_of_day: 6-22\n",
      "\n",
      "âœ… Verification: coffee_name still present with 8 types\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Parse Date and Time Columns\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ• STEP 3: DATETIME PARSING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Parse Date column\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "print(f\"\\nâœ… Date parsed: {df['Date'].min().date()} to {df['Date'].max().date()}\")\n",
    "\n",
    "# Create full datetime column (without corrupting Time)\n",
    "# Remove microseconds: \"10:15:50.520000\" â†’ \"10:15:50\"\n",
    "df['time_clean'] = df['Time'].astype(str).str.split('.').str[0]\n",
    "df['datetime'] = pd.to_datetime(\n",
    "    df['Date'].astype(str) + ' ' + df['time_clean'],\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Check quality\n",
    "bad_datetimes = df['datetime'].isna().sum()\n",
    "if bad_datetimes > 0:\n",
    "    print(f\"âš ï¸ Found {bad_datetimes} invalid datetimes - dropping them\")\n",
    "    df = df.dropna(subset=['datetime'])\n",
    "else:\n",
    "    print(f\"âœ… All {len(df):,} datetimes parsed successfully\")\n",
    "\n",
    "print(f\"   Range: {df['datetime'].min()} to {df['datetime'].max()}\")\n",
    "\n",
    "# Drop temporary column\n",
    "df = df.drop(columns=['time_clean'])\n",
    "\n",
    "# Extract hour if not already present\n",
    "df['hour_of_day'] = df['datetime'].dt.hour\n",
    "print(f\"\\nâ° Extracted hour_of_day: {df['hour_of_day'].min()}-{df['hour_of_day'].max()}\")\n",
    "\n",
    "# CRITICAL: Verify coffee_name still exists\n",
    "print(f\"\\nâœ… Verification: coffee_name still present with {df['coffee_name'].nunique()} types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ”§ STEP 4: TIME FEATURE ENGINEERING\n",
      "======================================================================\n",
      "\n",
      "âœ… Created time-based features:\n",
      "   â€¢ is_morning, is_afternoon, is_night\n",
      "   â€¢ is_peak_hour, is_morning_rush, is_evening_slow\n",
      "   â€¢ is_weekend, is_monday, is_friday\n",
      "   â€¢ weekday_morning_rush, weekend_afternoon\n",
      "\n",
      "ðŸ“Š Feature Distribution:\n",
      "   Morning transactions: 1,181 (33.3%)\n",
      "   Peak hour transactions: 1,732 (48.8%)\n",
      "   Weekend transactions: 889 (25.1%)\n",
      "\n",
      "âœ… Verification: coffee_name still present\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Feature Engineering - Time Features\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ”§ STEP 4: TIME FEATURE ENGINEERING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Time of day features\n",
    "df['is_morning'] = ((df['hour_of_day'] >= 6) & (df['hour_of_day'] < 12)).astype(int)\n",
    "df['is_afternoon'] = ((df['hour_of_day'] >= 12) & (df['hour_of_day'] < 18)).astype(int)\n",
    "df['is_night'] = ((df['hour_of_day'] >= 18) | (df['hour_of_day'] < 6)).astype(int)\n",
    "\n",
    "# Peak hours (high demand)\n",
    "df['is_peak_hour'] = df['hour_of_day'].isin([8, 9, 10, 12, 13, 14, 15]).astype(int)\n",
    "df['is_morning_rush'] = df['hour_of_day'].isin([8, 9, 10]).astype(int)\n",
    "df['is_evening_slow'] = df['hour_of_day'].isin([16, 17, 18, 19]).astype(int)\n",
    "\n",
    "# Day of week features\n",
    "df['is_weekend'] = df['Weekdaysort'].isin([6, 7]).astype(int)\n",
    "df['is_monday'] = (df['Weekdaysort'] == 1).astype(int)\n",
    "df['is_friday'] = (df['Weekdaysort'] == 5).astype(int)\n",
    "\n",
    "# Interaction features\n",
    "df['weekday_morning_rush'] = ((df['is_morning_rush'] == 1) & (df['is_weekend'] == 0)).astype(int)\n",
    "df['weekend_afternoon'] = ((df['is_afternoon'] == 1) & (df['is_weekend'] == 1)).astype(int)\n",
    "\n",
    "print(\"\\nâœ… Created time-based features:\")\n",
    "print(f\"   â€¢ is_morning, is_afternoon, is_night\")\n",
    "print(f\"   â€¢ is_peak_hour, is_morning_rush, is_evening_slow\")\n",
    "print(f\"   â€¢ is_weekend, is_monday, is_friday\")\n",
    "print(f\"   â€¢ weekday_morning_rush, weekend_afternoon\")\n",
    "\n",
    "# Feature distribution\n",
    "print(f\"\\nðŸ“Š Feature Distribution:\")\n",
    "print(f\"   Morning transactions: {df['is_morning'].sum():,} ({df['is_morning'].mean()*100:.1f}%)\")\n",
    "print(f\"   Peak hour transactions: {df['is_peak_hour'].sum():,} ({df['is_peak_hour'].mean()*100:.1f}%)\")\n",
    "print(f\"   Weekend transactions: {df['is_weekend'].sum():,} ({df['is_weekend'].mean()*100:.1f}%)\")\n",
    "\n",
    "# CRITICAL: Verify coffee_name still exists\n",
    "print(f\"\\nâœ… Verification: coffee_name still present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "â˜• STEP 5: PRODUCT FEATURE ENGINEERING\n",
      "======================================================================\n",
      "\n",
      "âœ… Created product features:\n",
      "   â€¢ is_premium_product\n",
      "\n",
      "ðŸ“Š Product Distribution:\n",
      "   Premium products: 1,806 (50.9%)\n",
      "\n",
      "ðŸ’° Average Price by Product:\n",
      "   Hot Chocolate             Â£35.99 (276 sales)\n",
      "   Cappuccino                Â£35.88 (486 sales)\n",
      "   Cocoa                     Â£35.65 (239 sales)\n",
      "   Latte                     Â£35.50 (757 sales)\n",
      "   Americano with Milk       Â£30.59 (809 sales)\n",
      "   Americano                 Â£25.98 (564 sales)\n",
      "   Cortado                   Â£25.73 (287 sales)\n",
      "   Espresso                  Â£20.85 (129 sales)\n",
      "\n",
      "âœ… Verification: coffee_name still present with 8 types\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Feature Engineering - Product Features\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"â˜• STEP 5: PRODUCT FEATURE ENGINEERING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# CRITICAL: Verify coffee_name exists before using it\n",
    "if 'coffee_name' not in df.columns:\n",
    "    raise KeyError(\"ERROR: coffee_name was accidentally dropped!\")\n",
    "\n",
    "# Define premium products (higher price point)\n",
    "premium_products = ['Latte', 'Hot Chocolate', 'Cappuccino', 'Cortado']\n",
    "df['is_premium_product'] = df['coffee_name'].isin(premium_products).astype(int)\n",
    "\n",
    "print(f\"\\nâœ… Created product features:\")\n",
    "print(f\"   â€¢ is_premium_product\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Product Distribution:\")\n",
    "print(f\"   Premium products: {df['is_premium_product'].sum():,} ({df['is_premium_product'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Average price by product type\n",
    "print(f\"\\nðŸ’° Average Price by Product:\")\n",
    "price_by_product = df.groupby('coffee_name')['money'].agg(['mean', 'count'])\n",
    "price_by_product = price_by_product.sort_values('mean', ascending=False)\n",
    "for product, row in price_by_product.iterrows():\n",
    "    print(f\"   {product:25} Â£{row['mean']:.2f} ({int(row['count']):,} sales)\")\n",
    "\n",
    "# CRITICAL: Verify coffee_name still exists\n",
    "print(f\"\\nâœ… Verification: coffee_name still present with {df['coffee_name'].nunique()} types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 6: PREPARE ML FEATURES (SELF-CONTAINED)\n",
      "======================================================================\n",
      "\n",
      "Loading fresh data...\n",
      "Loaded 3,547 rows\n",
      "coffee_name present with 8 types\n",
      "Features engineered\n",
      "coffee_name verified: 8 types\n",
      "\n",
      "Creating one-hot encoding...\n",
      "  Verifying coffee_name: True\n",
      "Created 8 coffee features:\n",
      "  - coffee_Americano: 564 transactions\n",
      "  - coffee_Americano with Milk: 809 transactions\n",
      "  - coffee_Cappuccino: 486 transactions\n",
      "  - coffee_Cocoa: 239 transactions\n",
      "  - coffee_Cortado: 287 transactions\n",
      "  - coffee_Espresso: 129 transactions\n",
      "  - coffee_Hot Chocolate: 276 transactions\n",
      "  - coffee_Latte: 757 transactions\n",
      "\n",
      "Feature matrix: (3547, 23)\n",
      "Target: 3547 samples\n",
      "\n",
      "======================================================================\n",
      "READY FOR MODEL TRAINING WITH 23 FEATURES\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: SELF-CONTAINED ML FEATURES (FIXED)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 6: PREPARE ML FEATURES (SELF-CONTAINED)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ALWAYS reload data fresh (safest approach)\n",
    "print(\"\\nLoading fresh data...\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/Coffe_sales.csv')\n",
    "print(f\"Loaded {len(df):,} rows\")\n",
    "\n",
    "# Verify coffee_name exists\n",
    "if 'coffee_name' not in df.columns:\n",
    "    print(f\"ERROR: coffee_name not in CSV!\")\n",
    "    print(f\"Available columns: {list(df.columns)}\")\n",
    "    raise KeyError(\"Source CSV is missing coffee_name column\")\n",
    "\n",
    "print(f\"coffee_name present with {df['coffee_name'].nunique()} types\")\n",
    "\n",
    "# Parse datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df['time_clean'] = df['Time'].astype(str).str.split('.').str[0]\n",
    "df['datetime'] = pd.to_datetime(df['Date'].astype(str) + ' ' + df['time_clean'], errors='coerce')\n",
    "df = df.drop(columns=['time_clean'])\n",
    "df['hour_of_day'] = df['datetime'].dt.hour\n",
    "\n",
    "# Time features\n",
    "df['is_morning'] = ((df['hour_of_day'] >= 6) & (df['hour_of_day'] < 12)).astype(int)\n",
    "df['is_afternoon'] = ((df['hour_of_day'] >= 12) & (df['hour_of_day'] < 18)).astype(int)\n",
    "df['is_night'] = ((df['hour_of_day'] >= 18) | (df['hour_of_day'] < 6)).astype(int)\n",
    "df['is_peak_hour'] = df['hour_of_day'].isin([8, 9, 10, 12, 13, 14, 15]).astype(int)\n",
    "df['is_morning_rush'] = df['hour_of_day'].isin([8, 9, 10]).astype(int)\n",
    "df['is_evening_slow'] = df['hour_of_day'].isin([16, 17, 18, 19]).astype(int)\n",
    "df['is_weekend'] = df['Weekdaysort'].isin([6, 7]).astype(int)\n",
    "df['is_monday'] = (df['Weekdaysort'] == 1).astype(int)\n",
    "df['is_friday'] = (df['Weekdaysort'] == 5).astype(int)\n",
    "df['weekday_morning_rush'] = ((df['is_morning_rush'] == 1) & (df['is_weekend'] == 0)).astype(int)\n",
    "df['weekend_afternoon'] = ((df['is_afternoon'] == 1) & (df['is_weekend'] == 1)).astype(int)\n",
    "\n",
    "# Product features\n",
    "premium_products = ['Latte', 'Hot Chocolate', 'Cappuccino', 'Cortado']\n",
    "df['is_premium_product'] = df['coffee_name'].isin(premium_products).astype(int)\n",
    "\n",
    "print(f\"Features engineered\")\n",
    "\n",
    "# Verify coffee_name STILL exists\n",
    "if 'coffee_name' not in df.columns:\n",
    "    print(\"ERROR: coffee_name disappeared during feature engineering!\")\n",
    "    print(f\"Current columns: {list(df.columns)}\")\n",
    "    raise KeyError(\"coffee_name was accidentally dropped\")\n",
    "\n",
    "print(f\"coffee_name verified: {df['coffee_name'].nunique()} types\")\n",
    "\n",
    "# ONE-HOT ENCODE COFFEE TYPES\n",
    "print(\"\\nCreating one-hot encoding...\")\n",
    "\n",
    "# Remove ONLY one-hot encoded columns (coffee_Latte, coffee_Americano, etc.)\n",
    "# DO NOT remove coffee_name!\n",
    "existing_coffee_cols = [col for col in df.columns if col.startswith('coffee_') and col != 'coffee_name']\n",
    "if len(existing_coffee_cols) > 0:\n",
    "    print(f\"  Removing {len(existing_coffee_cols)} existing one-hot columns\")\n",
    "    df = df.drop(columns=existing_coffee_cols)\n",
    "\n",
    "# Verify coffee_name exists RIGHT BEFORE encoding\n",
    "print(f\"  Verifying coffee_name: {'coffee_name' in df.columns}\")\n",
    "if 'coffee_name' not in df.columns:\n",
    "    print(f\"  ERROR - COLUMNS NOW: {list(df.columns)}\")\n",
    "    raise KeyError(\"coffee_name disappeared right before encoding!\")\n",
    "\n",
    "# One-hot encode\n",
    "coffee_dummies = pd.get_dummies(df['coffee_name'], prefix='coffee', dtype=int)\n",
    "df = pd.concat([df, coffee_dummies], axis=1)\n",
    "\n",
    "coffee_types = [col for col in df.columns if col.startswith('coffee_') and col != 'coffee_name']\n",
    "print(f\"Created {len(coffee_types)} coffee features:\")\n",
    "for coffee_col in sorted(coffee_types):\n",
    "    print(f\"  - {coffee_col}: {df[coffee_col].sum():,} transactions\")\n",
    "\n",
    "# Define features (exclude coffee_name itself, only use one-hot encoded versions)\n",
    "feature_columns = [\n",
    "    'hour_of_day', 'Weekdaysort', 'Monthsort',\n",
    "    'is_morning', 'is_afternoon', 'is_night',\n",
    "    'is_peak_hour', 'is_morning_rush', 'is_evening_slow',\n",
    "    'is_weekend', 'is_monday', 'is_friday',\n",
    "    'is_premium_product', 'weekday_morning_rush', 'weekend_afternoon'\n",
    "] + coffee_types\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[feature_columns].copy()\n",
    "y = df['money'].copy()\n",
    "\n",
    "print(f\"\\nFeature matrix: {X.shape}\")\n",
    "print(f\"Target: {len(y)} samples\")\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(f\"READY FOR MODEL TRAINING WITH {len(feature_columns)} FEATURES\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "âœ‚ï¸ STEP 7: TRAIN-TEST SPLIT\n",
      "======================================================================\n",
      "\n",
      "âœ… Data split complete:\n",
      "   Training set:   2,837 samples (80.0%)\n",
      "   Test set:       710 samples (20.0%)\n",
      "\n",
      "ðŸ“Š Target distribution:\n",
      "   Train mean: Â£31.61\n",
      "   Test mean:  Â£31.79\n"
     ]
    }
   ],
   "source": [
    "# CELL 8: Train-Test Split\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ‚ï¸ STEP 7: TRAIN-TEST SPLIT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Data split complete:\")\n",
    "print(f\"   Training set:   {len(X_train):,} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   Test set:       {len(X_test):,} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nðŸ“Š Target distribution:\")\n",
    "print(f\"   Train mean: Â£{y_train.mean():.2f}\")\n",
    "print(f\"   Test mean:  Â£{y_test.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸŽ¯ STEP 8: TRAIN BASELINE MODEL\n",
      "======================================================================\n",
      "\n",
      "ðŸ”„ Training XGBoost model...\n",
      "âœ… Model training complete!\n",
      "\n",
      "ðŸ“Š MODEL PERFORMANCE:\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Training Set:\n",
      "   RMSE: Â£0.53\n",
      "   MAE:  Â£0.25\n",
      "   RÂ²:   0.9884\n",
      "\n",
      "ðŸ“‰ Test Set:\n",
      "   RMSE: Â£0.70\n",
      "   MAE:  Â£0.34\n",
      "   RÂ²:   0.9783\n",
      "\n",
      "ðŸŽ¯ Model Accuracy:\n",
      "   Average prediction error: Â£0.34\n",
      "   Percentage error: 1.06%\n"
     ]
    }
   ],
   "source": [
    "# CELL 9: Train Baseline XGBoost Model\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸŽ¯ STEP 8: TRAIN BASELINE MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Train baseline model\n",
    "print(\"\\nðŸ”„ Training XGBoost model...\")\n",
    "model = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"âœ… Model training complete!\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nðŸ“Š MODEL PERFORMANCE:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nðŸ“ˆ Training Set:\")\n",
    "print(f\"   RMSE: Â£{train_rmse:.2f}\")\n",
    "print(f\"   MAE:  Â£{train_mae:.2f}\")\n",
    "print(f\"   RÂ²:   {train_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ“‰ Test Set:\")\n",
    "print(f\"   RMSE: Â£{test_rmse:.2f}\")\n",
    "print(f\"   MAE:  Â£{test_mae:.2f}\")\n",
    "print(f\"   RÂ²:   {test_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Model Accuracy:\")\n",
    "print(f\"   Average prediction error: Â£{test_mae:.2f}\")\n",
    "print(f\"   Percentage error: {(test_mae/y_test.mean())*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ’° STEP 9: BUSINESS IMPACT ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š CURRENT STATE (Static Pricing):\n",
      "   Total transactions: 3,547\n",
      "   Total revenue: Â£112,245.58\n",
      "   Average transaction: Â£31.65\n",
      "\n",
      "ðŸ’¡ DYNAMIC PRICING OPPORTUNITY:\n",
      "   Projected revenue: Â£117,010.55\n",
      "   Revenue lift: Â£4,764.97 (+4.2%)\n",
      "   Daily increase: Â£12.28\n",
      "   Annual projection: Â£4,482.51\n",
      "\n",
      "======================================================================\n",
      "KEY INSIGHT: Dynamic pricing could increase revenue by\n",
      "Â£4,764.97 (4.2%) based on demand patterns.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# CELL 10: Business Impact Analysis\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ’° STEP 9: BUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Current revenue\n",
    "current_revenue = df['money'].sum()\n",
    "avg_transaction = df['money'].mean()\n",
    "\n",
    "print(f\"\\nðŸ“Š CURRENT STATE (Static Pricing):\")\n",
    "print(f\"   Total transactions: {len(df):,}\")\n",
    "print(f\"   Total revenue: Â£{current_revenue:,.2f}\")\n",
    "print(f\"   Average transaction: Â£{avg_transaction:.2f}\")\n",
    "\n",
    "# Simulate dynamic pricing opportunity\n",
    "df_sim = df.copy()\n",
    "df_sim['dynamic_price'] = df_sim['money'].copy()\n",
    "\n",
    "# Apply price adjustments\n",
    "peak_mask = df_sim['is_peak_hour'] == 1\n",
    "evening_mask = (df_sim['hour_of_day'] >= 18) & (df_sim['hour_of_day'] <= 20)\n",
    "slow_mask = df_sim['is_evening_slow'] == 1\n",
    "\n",
    "df_sim.loc[peak_mask, 'dynamic_price'] *= 1.10\n",
    "df_sim.loc[evening_mask, 'dynamic_price'] *= 1.05\n",
    "df_sim.loc[slow_mask, 'dynamic_price'] *= 0.95\n",
    "\n",
    "# Calculate new revenue\n",
    "dynamic_revenue = df_sim['dynamic_price'].sum()\n",
    "revenue_lift = dynamic_revenue - current_revenue\n",
    "lift_percentage = (revenue_lift / current_revenue) * 100\n",
    "\n",
    "print(f\"\\nðŸ’¡ DYNAMIC PRICING OPPORTUNITY:\")\n",
    "print(f\"   Projected revenue: Â£{dynamic_revenue:,.2f}\")\n",
    "print(f\"   Revenue lift: Â£{revenue_lift:,.2f} (+{lift_percentage:.1f}%)\")\n",
    "print(f\"   Daily increase: Â£{revenue_lift/388:.2f}\")\n",
    "print(f\"   Annual projection: Â£{(revenue_lift/388)*365:,.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"KEY INSIGHT: Dynamic pricing could increase revenue by\")\n",
    "print(f\"Â£{revenue_lift:,.2f} ({lift_percentage:.1f}%) based on demand patterns.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ’¾ STEP 10: SAVE OUTPUTS\n",
      "======================================================================\n",
      "âœ… Saved: ../data/coffee_sales_cleaned.csv (3,547 rows, 32 columns)\n",
      "   Includes coffee_name: True\n",
      "âœ… Saved: ../model/baseline_xgboost.pkl\n",
      "âœ… Saved: ../model/feature_names.txt (23 features)\n",
      "âœ… Saved: ../model/baseline_metrics.csv\n",
      "\n",
      "======================================================================\n",
      "âœ… PHASE 1 COMPLETE: BASELINE MODEL READY\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Summary:\n",
      "   Model accuracy: RÂ² = 0.978, MAE = Â£0.34\n",
      "   Business impact: +Â£4,764.97 (4.2%)\n",
      "\n",
      "ðŸš€ Next: Phase 2 - Weather integration & hyperparameter tuning\n"
     ]
    }
   ],
   "source": [
    "# CELL 11: Save Outputs\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ’¾ STEP 10: SAVE OUTPUTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save cleaned data (WITH coffee_name preserved!)\n",
    "df.to_csv('../data/coffee_sales_cleaned.csv', index=False)\n",
    "print(f\"âœ… Saved: ../data/coffee_sales_cleaned.csv ({len(df):,} rows, {len(df.columns)} columns)\")\n",
    "print(f\"   Includes coffee_name: {'coffee_name' in df.columns}\")\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, '../model/baseline_xgboost.pkl')\n",
    "print(f\"âœ… Saved: ../model/baseline_xgboost.pkl\")\n",
    "\n",
    "# Save feature names\n",
    "with open('../model/feature_names.txt', 'w') as f:\n",
    "    for feature in feature_columns:\n",
    "        f.write(f\"{feature}\\n\")\n",
    "print(f\"âœ… Saved: ../model/feature_names.txt ({len(feature_columns)} features)\")\n",
    "\n",
    "# Save performance metrics\n",
    "metrics = {\n",
    "    'model': 'Baseline XGBoost',\n",
    "    'features': len(feature_columns),\n",
    "    'train_samples': len(X_train),\n",
    "    'test_samples': len(X_test),\n",
    "    'test_rmse': test_rmse,\n",
    "    'test_mae': test_mae,\n",
    "    'test_r2': test_r2,\n",
    "    'revenue_lift_gbp': revenue_lift,\n",
    "    'revenue_lift_pct': lift_percentage\n",
    "}\n",
    "\n",
    "pd.DataFrame([metrics]).to_csv('../model/baseline_metrics.csv', index=False)\n",
    "print(f\"âœ… Saved: ../model/baseline_metrics.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… PHASE 1 COMPLETE: BASELINE MODEL READY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nðŸ“Š Summary:\")\n",
    "print(f\"   Model accuracy: RÂ² = {test_r2:.3f}, MAE = Â£{test_mae:.2f}\")\n",
    "print(f\"   Business impact: +Â£{revenue_lift:,.2f} ({lift_percentage:.1f}%)\")\n",
    "print(f\"\\nðŸš€ Next: Phase 2 - Weather integration & hyperparameter tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ“‹ PHASE 1 EXECUTIVE SUMMARY\n",
      "======================================================================\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘               DATA EXPLORATION & BASELINE MODEL                      â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘                                                                      â•‘\n",
      "â•‘  ðŸ“Š DATASET                                                          â•‘\n",
      "â•‘     â€¢ Transactions: 3,547                                           â•‘\n",
      "â•‘     â€¢ Date range: 2024-03-01 to 2025-03-23               â•‘\n",
      "â•‘     â€¢ Features engineered: 23                                        â•‘\n",
      "â•‘     â€¢ Coffee types: 8                                           â•‘\n",
      "â•‘                                                                      â•‘\n",
      "â•‘  ðŸ¤– BASELINE MODEL (XGBoost)                                         â•‘\n",
      "â•‘     â€¢ Test RÂ²: 0.978                                               â•‘\n",
      "â•‘     â€¢ Test MAE: Â£0.34                                            â•‘\n",
      "â•‘     â€¢ Prediction error: 1.06%                                      â•‘\n",
      "â•‘                                                                      â•‘\n",
      "â•‘  ðŸ’° BUSINESS OPPORTUNITY                                             â•‘\n",
      "â•‘     â€¢ Current revenue: Â£112,245.58                          â•‘\n",
      "â•‘     â€¢ Dynamic pricing revenue: Â£117,010.55                  â•‘\n",
      "â•‘     â€¢ Revenue lift: Â£4,764.97 (+4.2%)                    â•‘\n",
      "â•‘     â€¢ Annual projection: Â£4,482.51                 â•‘\n",
      "â•‘                                                                      â•‘\n",
      "â•‘  ðŸŽ¯ KEY FINDINGS                                                     â•‘\n",
      "â•‘     â€¢ Peak hour (2 PM): 7x more demand than slow periods             â•‘\n",
      "â•‘     â€¢ Premium products: 50.9% of transactions              â•‘\n",
      "â•‘     â€¢ Weekend traffic: 25.1% of total                       â•‘\n",
      "â•‘                                                                      â•‘\n",
      "â•‘  âœ… PHASE 1 STATUS: COMPLETE                                         â•‘\n",
      "â•‘     Ready for Phase 2: Weather integration & model optimization      â•‘\n",
      "â•‘                                                                      â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ‰ CONGRATULATIONS! Phase 1 deliverables complete.\n",
      "   Your baseline model proves the concept works.\n",
      "   You now have quantified business impact to show recruiters.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Executive summary for portfolio presentation.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ“‹ PHASE 1 EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘               DATA EXPLORATION & BASELINE MODEL                      â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                                      â•‘\n",
    "â•‘  ðŸ“Š DATASET                                                          â•‘\n",
    "â•‘     â€¢ Transactions: {len(df):,}                                           â•‘\n",
    "â•‘     â€¢ Date range: {df['Date'].min().date()} to {df['Date'].max().date()}               â•‘\n",
    "â•‘     â€¢ Features engineered: {len(feature_columns)}                                        â•‘\n",
    "â•‘     â€¢ Coffee types: {df['coffee_name'].nunique()}                                           â•‘\n",
    "â•‘                                                                      â•‘\n",
    "â•‘  ðŸ¤– BASELINE MODEL (XGBoost)                                         â•‘\n",
    "â•‘     â€¢ Test RÂ²: {test_r2:.3f}                                               â•‘\n",
    "â•‘     â€¢ Test MAE: Â£{test_mae:.2f}                                            â•‘\n",
    "â•‘     â€¢ Prediction error: {(test_mae/y_test.mean())*100:.2f}%                                      â•‘\n",
    "â•‘                                                                      â•‘\n",
    "â•‘  ðŸ’° BUSINESS OPPORTUNITY                                             â•‘\n",
    "â•‘     â€¢ Current revenue: Â£{current_revenue:,.2f}                          â•‘\n",
    "â•‘     â€¢ Dynamic pricing revenue: Â£{dynamic_revenue:,.2f}                  â•‘\n",
    "â•‘     â€¢ Revenue lift: Â£{revenue_lift:,.2f} (+{lift_percentage:.1f}%)                    â•‘\n",
    "â•‘     â€¢ Annual projection: Â£{(revenue_lift/388)*365:,.2f}                 â•‘\n",
    "â•‘                                                                      â•‘\n",
    "â•‘  ðŸŽ¯ KEY FINDINGS                                                     â•‘\n",
    "â•‘     â€¢ Peak hour (2 PM): 7x more demand than slow periods             â•‘\n",
    "â•‘     â€¢ Premium products: {df['is_premium_product'].mean()*100:.1f}% of transactions              â•‘\n",
    "â•‘     â€¢ Weekend traffic: {df['is_weekend'].mean()*100:.1f}% of total                       â•‘\n",
    "â•‘                                                                      â•‘\n",
    "â•‘  âœ… PHASE 1 STATUS: COMPLETE                                         â•‘\n",
    "â•‘     Ready for Phase 2: Weather integration & model optimization      â•‘\n",
    "â•‘                                                                      â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸŽ‰ CONGRATULATIONS! Phase 1 deliverables complete.\")\n",
    "print(\"   Your baseline model proves the concept works.\")\n",
    "print(\"   You now have quantified business impact to show recruiters.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” CURRENT PROJECT STRUCTURE\n",
      "======================================================================\n",
      "\n",
      "Current directory: C:\\Users\\DELL\\Documents\\AI_PM_Projects\\ai-dynamic-pricing\\notebooks\n",
      "\n",
      "ðŸ“ Folders in current directory:\n",
      "\n",
      "ðŸ““ Notebook locations:\n",
      "   â€¢ 01_data_exploration.ipynb\n",
      "   â€¢ 02_weather_integration.ipynb\n",
      "   â€¢ 03_model_training_with_tuning.ipynb\n",
      "   â€¢ 04_backtest_engine.ipynb\n",
      "\n",
      "ðŸ“‚ Data folder check:\n",
      "   âœ… ../data/ exists (you're in a subfolder)\n",
      "\n",
      "ðŸ¤– Model folder check:\n",
      "   âœ… ../model/ exists (you're in a subfolder)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"ðŸ” CURRENT PROJECT STRUCTURE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check current directory\n",
    "print(f\"\\nCurrent directory: {os.getcwd()}\")\n",
    "\n",
    "# List all folders\n",
    "print(f\"\\nðŸ“ Folders in current directory:\")\n",
    "for item in os.listdir('.'):\n",
    "    if os.path.isdir(item) and not item.startswith('.'):\n",
    "        print(f\"   â€¢ {item}/\")\n",
    "\n",
    "# Find all notebooks\n",
    "print(f\"\\nðŸ““ Notebook locations:\")\n",
    "notebooks = glob.glob('**/*.ipynb', recursive=True)\n",
    "for nb in notebooks[:10]:  # Show first 10\n",
    "    print(f\"   â€¢ {nb}\")\n",
    "\n",
    "# Check if data folder exists\n",
    "print(f\"\\nðŸ“‚ Data folder check:\")\n",
    "if os.path.exists('./data'):\n",
    "    print(f\"   âœ… ./data/ exists\")\n",
    "    csv_files = [f for f in os.listdir('./data') if f.endswith('.csv')]\n",
    "    print(f\"   Found {len(csv_files)} CSV files:\")\n",
    "    for f in csv_files[:5]:\n",
    "        print(f\"      â€¢ {f}\")\n",
    "elif os.path.exists('../data'):\n",
    "    print(f\"   âœ… ../data/ exists (you're in a subfolder)\")\n",
    "else:\n",
    "    print(f\"   âŒ Can't find data folder\")\n",
    "\n",
    "# Check if model folder exists\n",
    "print(f\"\\nðŸ¤– Model folder check:\")\n",
    "if os.path.exists('./model'):\n",
    "    print(f\"   âœ… ./model/ exists\")\n",
    "elif os.path.exists('../model'):\n",
    "    print(f\"   âœ… ../model/ exists (you're in a subfolder)\")\n",
    "else:\n",
    "    print(f\"   âŒ Can't find model folder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
